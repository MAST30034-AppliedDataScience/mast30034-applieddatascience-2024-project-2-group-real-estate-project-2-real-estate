{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import jmespath\n",
    "import os\n",
    "from httpx import AsyncClient, Response\n",
    "from parsel import Selector\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   https://scrapfly.io/blog/how-to-scrape-domain-com-au-real-estate-property-data/\n",
    "\n",
    "# search page\n",
    "client = AsyncClient(\n",
    "    # enable http2\n",
    "    http2=True,\n",
    "    # add basic browser headers to mimize blocking chancesd\n",
    "    headers={\n",
    "        \"accept-language\": \"en-US,en;q=0.9\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n",
    "        \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"accept-language\": \"en-US;en;q=0.9\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br\",\n",
    "    }\n",
    ")\n",
    "\n",
    "def parse_search_page(data):\n",
    "    \"\"\"refine search pages data\"\"\"\n",
    "    if not data:\n",
    "        return    \n",
    "    data = data[\"listingsMap\"]\n",
    "    result = []\n",
    "    # iterate over card items in the search data\n",
    "    for key in data.keys():\n",
    "        item = data[key]\n",
    "        parsed_data = jmespath.search(\n",
    "            \"\"\"{\n",
    "        id: id,\n",
    "        listingType: listingType,\n",
    "        listingModel: listingModel\n",
    "      }\"\"\",\n",
    "        item,\n",
    "        )\n",
    "        # execulde the skeletonImages key from the data\n",
    "        parsed_data[\"listingModel\"].pop(\"skeletonImages\")\n",
    "        result.append(parsed_data)\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_hidden_data(response: Response):\n",
    "    \"\"\"parse json data from script tags\"\"\"\n",
    "    selector = Selector(response.text)\n",
    "    script = selector.xpath(\"//script[@id='__NEXT_DATA__']/text()\").get()\n",
    "    data = json.loads(script)\n",
    "    with open(\"newdata.json\", \"w\") as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "    return data[\"props\"][\"pageProps\"][\"componentProps\"]\n",
    "\n",
    "\n",
    "async def scrape_search(url: str, max_scrape_pages: int = None) -> List[Dict]:\n",
    "    \"\"\"scrape property listings from search pages\"\"\"\n",
    "    first_page = await client.get(url)\n",
    "    print(\"scraping search page {}\", url)\n",
    "    data = parse_hidden_data(first_page)\n",
    "    search_data = parse_search_page(data)\n",
    "    # get the number of maximum search pages\n",
    "    max_search_pages = data[\"totalPages\"]\n",
    "    # scrape all available pages if not max_scrape_pages or max_scrape_pages >= max_search_pages\n",
    "    if max_scrape_pages and max_scrape_pages < max_search_pages:\n",
    "        max_scrape_pages = max_scrape_pages\n",
    "    else:\n",
    "        max_scrape_pages = max_search_pages\n",
    "    print(f\"scraping search pagination, remaining ({max_scrape_pages - 1} more pages)\")\n",
    "    # add the remaining search pages to a scraping list\n",
    "    other_pages = [client.get(str(first_page.url) + f\"?page={page}\") for page in range(2, max_scrape_pages + 1)]\n",
    "    # scrape the remaining search pages concurrently\n",
    "    for response in asyncio.as_completed(other_pages):\n",
    "        response = await response\n",
    "        assert response.status_code == 200, \"request has been blocked\"        \n",
    "        # parse the data from script tag        \n",
    "        data = parse_hidden_data(response)\n",
    "        # aappend the data to the list after refining        \n",
    "        search_data.extend(parse_search_page(data))\n",
    "    print(f\"scraped ({len(search_data)}) from {url}\")\n",
    "    return search_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping search page {} https://www.domain.com.au/rent/werribee-vic-3030/\n",
      "scraping search pagination, remaining (44 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/box-hill-vic-3128/\n",
      "scraping search pagination, remaining (13 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/coburg-vic-3058/\n",
      "scraping search pagination, remaining (22 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/geelong-vic-3220/\n",
      "scraping search pagination, remaining (12 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/melbourne-vic-3000/\n",
      "scraping search pagination, remaining (49 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/footscray-vic-3011/\n",
      "scraping search pagination, remaining (28 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/richmond-vic-3121/\n",
      "scraping search pagination, remaining (49 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/west-melbourne-vic-3003/\n",
      "scraping search pagination, remaining (49 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/south-yarra-vic-3141/\n",
      "scraping search pagination, remaining (49 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/hawthorn-vic-3122/\n",
      "scraping search pagination, remaining (26 more pages)\n",
      "scraping search page {} https://www.domain.com.au/sale/carlton-vic-3053/\n",
      "scraping search pagination, remaining (49 more pages)\n",
      "scraping search page {} https://www.domain.com.au/rent/brunswick-vic-3056/\n",
      "scraping search pagination, remaining (15 more pages)\n",
      "scraped (895) from https://www.domain.com.au/rent/werribee-vic-3030/\n",
      "Scraped and saved data for werribee-vic-3030 to ../data/raw/property_data_json/property_data_werribee-vic-3030.json\n",
      "scraped (267) from https://www.domain.com.au/rent/box-hill-vic-3128/\n",
      "Scraped and saved data for box-hill-vic-3128 to ../data/raw/property_data_json/property_data_box-hill-vic-3128.json\n",
      "scraped (448) from https://www.domain.com.au/rent/coburg-vic-3058/\n",
      "Scraped and saved data for coburg-vic-3058 to ../data/raw/property_data_json/property_data_coburg-vic-3058.json\n",
      "scraped (243) from https://www.domain.com.au/rent/geelong-vic-3220/\n",
      "Scraped and saved data for geelong-vic-3220 to ../data/raw/property_data_json/property_data_geelong-vic-3220.json\n",
      "scraped (1000) from https://www.domain.com.au/rent/melbourne-vic-3000/\n",
      "Scraped and saved data for melbourne-vic-3000 to ../data/raw/property_data_json/property_data_melbourne-vic-3000.json\n",
      "scraped (563) from https://www.domain.com.au/rent/footscray-vic-3011/\n",
      "Scraped and saved data for footscray-vic-3011 to ../data/raw/property_data_json/property_data_footscray-vic-3011.json\n",
      "scraped (1000) from https://www.domain.com.au/rent/richmond-vic-3121/\n",
      "Scraped and saved data for richmond-vic-3121 to ../data/raw/property_data_json/property_data_richmond-vic-3121.json\n",
      "scraped (1000) from https://www.domain.com.au/rent/west-melbourne-vic-3003/\n",
      "Scraped and saved data for west-melbourne-vic-3003 to ../data/raw/property_data_json/property_data_west-melbourne-vic-3003.json\n",
      "scraped (1000) from https://www.domain.com.au/rent/south-yarra-vic-3141/\n",
      "Scraped and saved data for south-yarra-vic-3141 to ../data/raw/property_data_json/property_data_south-yarra-vic-3141.json\n",
      "scraped (538) from https://www.domain.com.au/rent/hawthorn-vic-3122/\n",
      "Scraped and saved data for hawthorn-vic-3122 to ../data/raw/property_data_json/property_data_hawthorn-vic-3122.json\n",
      "scraped (1022) from https://www.domain.com.au/sale/carlton-vic-3053/\n",
      "Scraped and saved data for carlton-vic-3053 to ../data/raw/property_data_json/property_data_carlton-vic-3053.json\n",
      "scraped (316) from https://www.domain.com.au/rent/brunswick-vic-3056/\n",
      "Scraped and saved data for brunswick-vic-3056 to ../data/raw/property_data_json/property_data_brunswick-vic-3056.json\n"
     ]
    }
   ],
   "source": [
    "# List of suburb URLs\n",
    "suburb_urls = [\n",
    "    \"https://www.domain.com.au/rent/melbourne-vic-3000/\",\n",
    "    \"https://www.domain.com.au/sale/carlton-vic-3053/\",\n",
    "    \"https://www.domain.com.au/rent/west-melbourne-vic-3003/\",\n",
    "    \"https://www.domain.com.au/rent/south-yarra-vic-3141/\",\n",
    "    \"https://www.domain.com.au/rent/hawthorn-vic-3122/\",\n",
    "    \"https://www.domain.com.au/rent/footscray-vic-3011/\",\n",
    "    \"https://www.domain.com.au/rent/brunswick-vic-3056/\",\n",
    "    \"https://www.domain.com.au/rent/richmond-vic-3121/\",\n",
    "    \"https://www.domain.com.au/rent/box-hill-vic-3128/\",\n",
    "    \"https://www.domain.com.au/rent/werribee-vic-3030/\",\n",
    "    \"https://www.domain.com.au/rent/coburg-vic-3058/\",\n",
    "    \"https://www.domain.com.au/rent/geelong-vic-3220/\",    \n",
    "]\n",
    "\n",
    "async def scrape_and_save(url: str, max_scrape_pages: int):\n",
    "    \"\"\"Scrape property data from a given URL and save it to a JSON file.\"\"\"\n",
    "    data = await scrape_search(url=url, max_scrape_pages=max_scrape_pages)\n",
    "    \n",
    "    # Generate a file name based on the suburb name\n",
    "    suburb_name = url.split('/')[-2]  # Extracts 'melbourne-vic-3000' from URL\n",
    "    \n",
    "\n",
    "    # Define the directory path where you want to save the JSON files\n",
    "    directory_path = Path(\"../data/raw/property_data_json\")\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    directory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define the file name with the suburb name\n",
    "    file_name = f\"property_data_{suburb_name}.json\"\n",
    "\n",
    "    # Combine the directory path and file name\n",
    "    file_path = directory_path / file_name\n",
    "\n",
    "    # Save the data to a JSON file at the specified path\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Scraped and saved data for {suburb_name} to {file_path}\")\n",
    "\n",
    "\n",
    "async def run():\n",
    "    \"\"\"Scrape data for multiple suburbs concurrently.\"\"\"\n",
    "    tasks = [scrape_and_save(url, max_scrape_pages=50) for url in suburb_urls]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Start the scraping process\n",
    "await run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/property_data_json/property_data_west-melbourne-vic-3003.json', 'r') as file:\n",
    "    west_melbourne = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_south-yarra-vic-3141.json', 'r') as file:\n",
    "    south_yarra = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_melbourne-vic-3000.json', 'r') as file:\n",
    "    melbourne = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_hawthorn-vic-3122.json', 'r') as file:\n",
    "    hawthorn = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_footscray-vic-3011.json', 'r') as file:\n",
    "    footscray = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_carlton-vic-3053.json', 'r') as file:\n",
    "    carlton = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_brunswick-vic-3056.json', 'r') as file:\n",
    "    brunswick = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_box-hill-vic-3128.json', 'r') as file:\n",
    "    box_hill = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_coburg-vic-3058.json', 'r') as file:\n",
    "    coburg = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_geelong-vic-3220.json', 'r') as file:\n",
    "    geelong = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_richmond-vic-3121.json', 'r') as file:\n",
    "    richmond = json.load(file)\n",
    "\n",
    "with open('../data/raw/property_data_json/property_data_werribee-vic-3030.json', 'r') as file:\n",
    "    werribee = json.load(file)\n",
    "\n",
    "\n",
    "# Extract features from 'listingModel'\n",
    "def extract_listing_features(json_data):\n",
    "    data = []\n",
    "    for item in json_data:\n",
    "        if 'listingModel' in item:\n",
    "            listing_model = item['listingModel']\n",
    "            # Extracting top-level features\n",
    "            features = {\n",
    "                'id': item.get('id'),\n",
    "                'promoType': listing_model.get('promoType'),\n",
    "                'price':listing_model.get('price'),\n",
    "                'hasVideo':listing_model.get('hasVideo'),\n",
    "                'agentNames':listing_model.get('branding', {}).get('agentNames'),\n",
    "                'brandName':listing_model.get('branding', {}).get('brandName'),\n",
    "                'addressStreet': listing_model.get('address', {}).get('street'),\n",
    "                'addressSuburb': listing_model.get('address', {}).get('suburb'),\n",
    "                'addressState': listing_model.get('address', {}).get('state'),\n",
    "                'addressPostcode': listing_model.get('address', {}).get('postcode'),\n",
    "                'addressLat': listing_model.get('address', {}).get('lat'),\n",
    "                'addressLng': listing_model.get('address', {}).get('lng'),\n",
    "                'num_bath': listing_model.get('features',{}).get('baths'),\n",
    "                'type': listing_model.get('features', {}).get('propertyType'),\n",
    "                'formatted': listing_model.get('features', {}).get('propertyTypeFormatted'),\n",
    "                'isRural': listing_model.get('features', {}).get('isRural'),\n",
    "                'landSize': listing_model.get('features', {}).get('landSize'),\n",
    "                'Retirement': listing_model.get('features', {}).get('isRetirement')\n",
    "            }\n",
    "            data.append(features)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "west_melbourne_df = extract_listing_features(west_melbourne)\n",
    "south_yarra_df = extract_listing_features(south_yarra)\n",
    "melbourne_df = extract_listing_features(melbourne)\n",
    "hawthorn_df = extract_listing_features(hawthorn)\n",
    "footscray_df = extract_listing_features(footscray)\n",
    "carlton_df = extract_listing_features(carlton)\n",
    "brunswick_df = extract_listing_features(brunswick)\n",
    "box_hill_df = extract_listing_features(box_hill)\n",
    "coburg_df = extract_listing_features(coburg)\n",
    "geelong_df = extract_listing_features(geelong)\n",
    "richmond_df = extract_listing_features(richmond)\n",
    "werribee_df = extract_listing_features(werribee)\n",
    "\n",
    "result = pd.concat([west_melbourne_df, south_yarra_df,melbourne_df,hawthorn_df,footscray_df,carlton_df,\n",
    "                    brunswick_df,box_hill_df,coburg_df,geelong_df,richmond_df,werribee_df], ignore_index=True)\n",
    "# Display DataFrame\n",
    "result.to_csv('../data/raw/domain.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
